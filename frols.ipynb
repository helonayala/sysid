{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMhG7SdphjMG7XYBSUrsxtU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/helonayala/sysid/blob/main/frols.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Forward-regression orthogonal least squares\n",
        "\n",
        "The method consists of using OLS for ranking the model candidate terms by ERR.\n",
        "\n",
        "The example below implements the Example 3.6 given in the book by Billings, 2013.\n",
        "\n",
        "## Imports and helper functions"
      ],
      "metadata": {
        "id": "nP5AvaAcLOu2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "UKC6T4S9EoWS"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from itertools import combinations_with_replacement\n",
        "import pandas as pd # Optional: for prettier display in the example\n",
        "\n",
        "# Helper function to create the basic ARX matrix\n",
        "def regMatARX(y_signal_in,\n",
        "              u_signal_in,\n",
        "              ny: int,\n",
        "              nu: int):\n",
        "    \"\"\"\n",
        "    Creates the initial ARX regression matrix and the target vector y(k).\n",
        "    AR (y-lag) terms are NOT negated.\n",
        "\n",
        "    Args:\n",
        "        y_signal_in (array-like): Output data vector.\n",
        "        u_signal_in (array-like): Input data vector.\n",
        "        ny (int): Number of past y lags (autoregressive order).\n",
        "        nu (int): Number of past u lags (exogenous input order).\n",
        "\n",
        "    Returns:\n",
        "        P0_data (np.ndarray): The ARX regressor matrix. Shape (NP, ny + nu).\n",
        "        P0_colnames (list): Column names for P0_data.\n",
        "        y_target (np.ndarray): The target vector y(k). Shape (NP,).\n",
        "    \"\"\"\n",
        "    if not isinstance(y_signal_in, np.ndarray):\n",
        "        y_signal = np.array(y_signal_in, dtype=float)\n",
        "    else:\n",
        "        y_signal = y_signal_in.astype(float)\n",
        "\n",
        "    if not isinstance(u_signal_in, np.ndarray):\n",
        "        u_signal = np.array(u_signal_in, dtype=float)\n",
        "    else:\n",
        "        u_signal = u_signal_in.astype(float)\n",
        "\n",
        "    if len(y_signal) != len(u_signal):\n",
        "        raise ValueError(\"Input signals y_signal and u_signal must have the same length.\")\n",
        "    if ny < 0 or nu < 0:\n",
        "        raise ValueError(\"Lags ny and nu must be non-negative.\")\n",
        "\n",
        "    N_total_samples = len(y_signal)\n",
        "\n",
        "    max_lag = 0\n",
        "    if ny > 0:\n",
        "        max_lag = max(max_lag, ny)\n",
        "    if nu > 0:\n",
        "        max_lag = max(max_lag, nu)\n",
        "\n",
        "    # Target vector y(k)\n",
        "    # These are the y values that each row of regressors corresponds to.\n",
        "    y_target = y_signal[max_lag:]\n",
        "    num_effective_rows = len(y_target)\n",
        "\n",
        "    P0_colnames = []\n",
        "    if ny > 0:\n",
        "        P0_colnames.extend([f'y(k-{i})' for i in range(1, ny + 1)])\n",
        "    if nu > 0:\n",
        "        P0_colnames.extend([f'u(k-{i})' for i in range(1, nu + 1)])\n",
        "    num_P0_cols = len(P0_colnames)\n",
        "\n",
        "    if num_effective_rows == 0: # Not enough data to form any rows\n",
        "        return np.empty((0, num_P0_cols), dtype=float), P0_colnames, np.empty((0,), dtype=float)\n",
        "\n",
        "    P0_rows_list = []\n",
        "    for k_target_idx in range(max_lag, N_total_samples):\n",
        "        current_regressor_row = []\n",
        "        # Add y lags: y(k-j) means y_signal[k_target_idx - j_lag] (NO NEGATION)\n",
        "        for j_lag_idx in range(1, ny + 1):\n",
        "            current_regressor_row.append(y_signal[k_target_idx - j_lag_idx])\n",
        "\n",
        "        for j_lag_idx in range(1, nu + 1):\n",
        "            current_regressor_row.append(u_signal[k_target_idx - j_lag_idx])\n",
        "        P0_rows_list.append(current_regressor_row)\n",
        "\n",
        "    P0_data = np.array(P0_rows_list, dtype=float)\n",
        "\n",
        "    return P0_data, P0_colnames, y_target\n",
        "\n",
        "\n",
        "def regMatNARX(u_signal_in,\n",
        "               y_signal_in,\n",
        "               nu: int,\n",
        "               ny: int,\n",
        "               poly_order_l: int):\n",
        "    \"\"\"\n",
        "    Generates the regression matrix for a NARX model with power-form polynomial terms,\n",
        "    and the corresponding target vector y(k).\n",
        "    AR (y-lag) terms in the base regressors are NOT negated.\n",
        "\n",
        "    Args:\n",
        "        u_signal_in (array-like): Input data vector.\n",
        "        y_signal_in (array-like): Output data vector.\n",
        "        nu (int): Order of the X part (number of u lags).\n",
        "        ny (int): Order of the AR part (number of y lags).\n",
        "        poly_order_l (int): Maximum order of the polynomial terms. Must be >= 1.\n",
        "\n",
        "    Returns:\n",
        "        P_final_data (np.ndarray): The final NARX regression matrix.\n",
        "        P_final_colnames (list): Column names for P_final_data.\n",
        "        y_target (np.ndarray): The target vector y(k).\n",
        "    \"\"\"\n",
        "    if not isinstance(y_signal_in, np.ndarray):\n",
        "        y_signal = np.array(y_signal_in, dtype=float)\n",
        "    else:\n",
        "        y_signal = y_signal_in.astype(float)\n",
        "\n",
        "    if not isinstance(u_signal_in, np.ndarray):\n",
        "        u_signal = np.array(u_signal_in, dtype=float)\n",
        "    else:\n",
        "        u_signal = u_signal_in.astype(float)\n",
        "\n",
        "    if len(y_signal) != len(u_signal):\n",
        "        raise ValueError(\"Input signals y_signal and u_signal must have the same length.\")\n",
        "    if ny < 0 or nu < 0:\n",
        "        raise ValueError(\"Lags ny and nu must be non-negative.\")\n",
        "    if poly_order_l < 1:\n",
        "        raise ValueError(\"Polynomial order 'poly_order_l' must be at least 1.\")\n",
        "\n",
        "    # Create the initial ARX regressors and target vector\n",
        "    # Note: regMatARX expects (y, u, ny, nu) order\n",
        "    P0_data, P0_colnames, y_target = regMatARX(y_signal, u_signal, ny, nu)\n",
        "\n",
        "    NP = len(y_target) # Number of effective rows\n",
        "\n",
        "    if NP == 0:\n",
        "        P_columns_list = [np.empty((0, 1), dtype=float)] # Constant term\n",
        "    else:\n",
        "        P_columns_list = [np.ones((NP, 1), dtype=float)] # Constant term\n",
        "\n",
        "    P_final_colnames = ['constant']\n",
        "\n",
        "    P_columns_list.append(P0_data)\n",
        "    P_final_colnames.extend(P0_colnames)\n",
        "\n",
        "    num_P0_base_regressors = P0_data.shape[1]\n",
        "\n",
        "    if poly_order_l >= 2 and num_P0_base_regressors > 0:\n",
        "        for current_poly_order in range(2, poly_order_l + 1):\n",
        "            for col_indices_tuple in combinations_with_replacement(range(num_P0_base_regressors), current_poly_order):\n",
        "                selected_P0_cols_for_product = P0_data[:, list(col_indices_tuple)]\n",
        "                new_poly_term_column = np.prod(selected_P0_cols_for_product, axis=1, keepdims=True)\n",
        "                P_columns_list.append(new_poly_term_column)\n",
        "\n",
        "                term_name = \"\".join([P0_colnames[i] for i in col_indices_tuple])\n",
        "                P_final_colnames.append(term_name)\n",
        "\n",
        "    if not P_columns_list:\n",
        "        P_final_data = np.empty((0, len(P_final_colnames)), dtype=float)\n",
        "    else:\n",
        "        P_final_data = np.concatenate(P_columns_list, axis=1)\n",
        "\n",
        "    return P_final_data, P_final_colnames, y_target"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we run some examples for synthetic data of ARX and NARX (power-form polynomials) regression matrices."
      ],
      "metadata": {
        "id": "BBTOmGlWLmy7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data\n",
        "u_data = np.array([0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8])\n",
        "y_data = np.array([1.0, 1.1, 1.2, 1.3, 1.4, 1.5, 1.6, 1.7]) # y(0) to y(7)\n",
        "\n",
        "# Model parameters for NARX\n",
        "nu_order_narx = 5  # u(k-1)\n",
        "ny_order_narx = 5  # y(k-1), y(k-2)\n",
        "poly_degree_narx = 2 # Up to quadratic terms\n",
        "\n",
        "# Generate the NARX regression matrix and target vector\n",
        "# Calling regMatNARX(u, y, nu, ny, l)\n",
        "narx_matrix, narx_colnames, narx_y_target = regMatNARX(\n",
        "    u_data, y_data, nu_order_narx, ny_order_narx, poly_degree_narx\n",
        ")\n",
        "\n",
        "print(\"--- NARX Model ---\")\n",
        "print(f\"Target y(k) vector (shape {narx_y_target.shape}):\")\n",
        "print(narx_y_target) # Should be y_data[max_lag:] = y_data[2:] = [1.2, 1.3, ..., 1.7]\n",
        "\n",
        "# Optional: Display using pandas DataFrame\n",
        "# Create a DataFrame for regressors\n",
        "df_narx_regressors = pd.DataFrame(narx_matrix, columns=narx_colnames)\n",
        "# Add the target vector as the first column for easy inspection\n",
        "df_narx_full = pd.concat(\n",
        "    [pd.DataFrame(narx_y_target, columns=['y(k)_target']), df_narx_regressors],\n",
        "    axis=1\n",
        ")\n",
        "print(\"\\nNARX Regression Matrix (P) and Target y(k):\")\n",
        "print(df_narx_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PcRcBw_CJRSA",
        "outputId": "e0ef2f18-75fd-453e-fe2e-d765f6674781"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- NARX Model ---\n",
            "Target y(k) vector (shape (3,)):\n",
            "[1.5 1.6 1.7]\n",
            "\n",
            "NARX Regression Matrix (P) and Target y(k):\n",
            "   y(k)_target  constant  y(k-1)  y(k-2)  y(k-3)  y(k-4)  y(k-5)  u(k-1)  \\\n",
            "0          1.5       1.0     1.4     1.3     1.2     1.1     1.0     0.5   \n",
            "1          1.6       1.0     1.5     1.4     1.3     1.2     1.1     0.6   \n",
            "2          1.7       1.0     1.6     1.5     1.4     1.3     1.2     0.7   \n",
            "\n",
            "   u(k-2)  u(k-3)  ...  u(k-2)u(k-2)  u(k-2)u(k-3)  u(k-2)u(k-4)  \\\n",
            "0     0.4     0.3  ...          0.16          0.12          0.08   \n",
            "1     0.5     0.4  ...          0.25          0.20          0.15   \n",
            "2     0.6     0.5  ...          0.36          0.30          0.24   \n",
            "\n",
            "   u(k-2)u(k-5)  u(k-3)u(k-3)  u(k-3)u(k-4)  u(k-3)u(k-5)  u(k-4)u(k-4)  \\\n",
            "0          0.04          0.09          0.06          0.03          0.04   \n",
            "1          0.10          0.16          0.12          0.08          0.09   \n",
            "2          0.18          0.25          0.20          0.15          0.16   \n",
            "\n",
            "   u(k-4)u(k-5)  u(k-5)u(k-5)  \n",
            "0          0.02          0.01  \n",
            "1          0.06          0.04  \n",
            "2          0.12          0.09  \n",
            "\n",
            "[3 rows x 67 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Example for regMatARX (Linear ARX) ---\n",
        "print(\"\\n\\n--- ARX Model (Linear Terms Only) ---\")\n",
        "ny_order_arx = 2\n",
        "nu_order_arx = 1\n",
        "# Calling regMatARX(y, u, ny, nu)\n",
        "arx_P0_matrix, arx_P0_colnames, arx_y_target = regMatARX(\n",
        "    y_data, u_data, ny_order_arx, nu_order_arx\n",
        ")\n",
        "\n",
        "print(f\"Target y(k) vector for ARX (shape {arx_y_target.shape}):\")\n",
        "print(arx_y_target)\n",
        "\n",
        "df_arx_P0_regressors = pd.DataFrame(arx_P0_matrix, columns=arx_P0_colnames)\n",
        "df_arx_full = pd.concat(\n",
        "    [pd.DataFrame(arx_y_target, columns=['y(k)_target']), df_arx_P0_regressors],\n",
        "    axis=1\n",
        ")\n",
        "print(\"\\nARX Regression Matrix (P0) and Target y(k):\")\n",
        "print(df_arx_full)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WiRdr36XKm_E",
        "outputId": "ba1a2cab-dc6f-4594-d692-bb10ebd19bc1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "--- ARX Model (Linear Terms Only) ---\n",
            "Target y(k) vector for ARX (shape (6,)):\n",
            "[1.2 1.3 1.4 1.5 1.6 1.7]\n",
            "\n",
            "ARX Regression Matrix (P0) and Target y(k):\n",
            "   y(k)_target  y(k-1)  y(k-2)  u(k-1)\n",
            "0          1.2     1.1     1.0     0.2\n",
            "1          1.3     1.2     1.1     0.3\n",
            "2          1.4     1.3     1.2     0.4\n",
            "3          1.5     1.4     1.3     0.5\n",
            "4          1.6     1.5     1.4     0.6\n",
            "5          1.7     1.6     1.5     0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FROLS implementation\n",
        "\n",
        "Next we write the FROLS function to proceed with term selection of NARX polynomial full models. This has been translated from R to python."
      ],
      "metadata": {
        "id": "toOCsWU_Pv0l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FROLS Function ---\n",
        "def frols(P_regressors, Y_target_in, rho, P_colnames=None, epsilon=1e-12):\n",
        "    \"\"\"\n",
        "    Forward Orthogonal Least Squares algorithm for model term selection and parameter estimation.\n",
        "\n",
        "    Args:\n",
        "        P_regressors (np.ndarray): Candidate regressor matrix (NP, M).\n",
        "        Y_target_in (np.ndarray): Target vector (NP,) or (NP,1).\n",
        "        rho (float): Error reduction ratio threshold for stopping.\n",
        "        P_colnames (list, optional): Names of columns in P_regressors.\n",
        "        epsilon (float, optional): Small value for numerical stability.\n",
        "\n",
        "    Returns:\n",
        "        dict: A dictionary containing selected terms, parameters, and other metrics.\n",
        "              Keys: 'th', 'Psel_data', 'Psel_colnames', 'g', 'W', 'A',\n",
        "                    'ERR_values', 'selected_indices'.\n",
        "    \"\"\"\n",
        "    if Y_target_in.ndim == 1:\n",
        "        Y_target = Y_target_in.reshape(-1, 1)\n",
        "    else:\n",
        "        Y_target = Y_target_in\n",
        "\n",
        "    M = P_regressors.shape[1]  # Number of candidate regressors\n",
        "    NP = P_regressors.shape[0] # Number of data points\n",
        "\n",
        "    # Handle edge cases\n",
        "    empty_result = {\n",
        "        'th': np.array([]), 'Psel_data': np.empty((NP,0)), 'Psel_colnames': [],\n",
        "        'g': np.array([]), 'W': np.empty((NP,0)), 'A': np.empty((0,0)),\n",
        "        'ERR_values': np.array([]), 'selected_indices': []\n",
        "    }\n",
        "    if NP == 0 or M == 0:\n",
        "        return empty_result\n",
        "\n",
        "    sig_yy_val = (Y_target.T @ Y_target).item()\n",
        "    if sig_yy_val < epsilon:\n",
        "        sig_yy_val = epsilon # Avoid division by zero if Y is zero vector\n",
        "\n",
        "    selected_terms_indices = []\n",
        "    err_selected_list = []\n",
        "    g_selected_list = []\n",
        "    Q_orthogonal_bases = np.empty((NP, 0))\n",
        "    A_matrix = np.empty((0,0))\n",
        "\n",
        "    M0 = 0 # Number of selected terms\n",
        "\n",
        "    for s_term_iter in range(M): # Iterate at most M times to select M terms\n",
        "\n",
        "        current_ERRs = np.full(M, -np.inf) # ERR for all M candidate terms in this iteration\n",
        "        current_gs = np.zeros(M)           # g for all M candidate terms\n",
        "        current_Qs_storage = np.zeros((NP, M)) # Storage for orthogonalized candidates\n",
        "\n",
        "        if s_term_iter == 0: # Selecting the first term\n",
        "            for m_idx in range(M):\n",
        "                p_m = P_regressors[:, m_idx:m_idx+1]\n",
        "                p_m_norm_sq = (p_m.T @ p_m).item()\n",
        "                if p_m_norm_sq >= epsilon:\n",
        "                    # For the first term, Q_m = P_m\n",
        "                    current_Qs_storage[:,m_idx] = p_m.flatten() # Store P_m as Q_m\n",
        "                    current_gs[m_idx] = (Y_target.T @ p_m).item() / p_m_norm_sq\n",
        "                    current_ERRs[m_idx] = (current_gs[m_idx]**2 * p_m_norm_sq) / sig_yy_val\n",
        "        else: # Selecting subsequent terms (s_term_iter > 0)\n",
        "            for m_idx in range(M):\n",
        "                if m_idx in selected_terms_indices: # Skip already selected terms\n",
        "                    continue\n",
        "\n",
        "                p_m = P_regressors[:, m_idx:m_idx+1]\n",
        "                q_m_orth = p_m.copy() # Start with P_m\n",
        "\n",
        "                # Orthogonalize P_m against previously selected Q_orthogonal_bases\n",
        "                for r_q_idx in range(M0): # M0 is number of terms already in Q_orthogonal_bases\n",
        "                    q_r = Q_orthogonal_bases[:, r_q_idx:r_q_idx+1]\n",
        "                    q_r_norm_sq = (q_r.T @ q_r).item()\n",
        "                    alpha_mr = 0.0\n",
        "                    if q_r_norm_sq >= epsilon:\n",
        "                        alpha_mr = (p_m.T @ q_r).item() / q_r_norm_sq\n",
        "                    q_m_orth -= alpha_mr * q_r\n",
        "\n",
        "                current_Qs_storage[:,m_idx] = q_m_orth.flatten()\n",
        "                q_m_orth_norm_sq = (q_m_orth.T @ q_m_orth).item()\n",
        "\n",
        "                if q_m_orth_norm_sq >= epsilon:\n",
        "                    current_gs[m_idx] = (Y_target.T @ q_m_orth).item() / q_m_orth_norm_sq\n",
        "                    current_ERRs[m_idx] = (current_gs[m_idx]**2 * q_m_orth_norm_sq) / sig_yy_val\n",
        "\n",
        "        if np.all(np.isneginf(current_ERRs)): # No more terms can be selected\n",
        "            break\n",
        "\n",
        "        newly_selected_idx = np.argmax(current_ERRs)\n",
        "\n",
        "        # Store results for the newly selected term\n",
        "        selected_terms_indices.append(newly_selected_idx)\n",
        "        err_selected_list.append(current_ERRs[newly_selected_idx])\n",
        "        g_selected_list.append(current_gs[newly_selected_idx])\n",
        "\n",
        "        Q_selected_term = current_Qs_storage[:, newly_selected_idx:newly_selected_idx+1]\n",
        "        if Q_orthogonal_bases.shape[1] == 0: # First term\n",
        "            Q_orthogonal_bases = Q_selected_term\n",
        "        else:\n",
        "            Q_orthogonal_bases = np.hstack((Q_orthogonal_bases, Q_selected_term))\n",
        "\n",
        "        # Update A matrix\n",
        "        p_original_newly_selected = P_regressors[:, newly_selected_idx:newly_selected_idx+1]\n",
        "        if M0 == 0: # First term selected\n",
        "            A_matrix = np.array([[1.0]])\n",
        "        else:\n",
        "            A_new_col = np.zeros((M0, 1))\n",
        "            for r_A_idx in range(M0):\n",
        "                q_r_for_A = Q_orthogonal_bases[:, r_A_idx:r_A_idx+1] # These are from previous Qs\n",
        "                q_r_for_A_norm_sq = (q_r_for_A.T @ q_r_for_A).item()\n",
        "                if q_r_for_A_norm_sq >= epsilon:\n",
        "                    A_new_col[r_A_idx, 0] = (p_original_newly_selected.T @ q_r_for_A).item() / q_r_for_A_norm_sq\n",
        "\n",
        "            A_matrix = np.block([\n",
        "                [A_matrix, A_new_col],\n",
        "                [np.zeros((1, M0)), np.array([[1.0]])]\n",
        "            ])\n",
        "        M0 += 1 # Increment number of selected terms\n",
        "\n",
        "        # Check stopping criterion\n",
        "        esr = 1.0 - np.sum(err_selected_list)\n",
        "        if esr <= rho:\n",
        "            break\n",
        "\n",
        "    if M0 == 0: # No terms were selected at all\n",
        "        return empty_result\n",
        "\n",
        "    # Final parameter calculation: A * theta = g\n",
        "    A_final = A_matrix # This is M0 x M0\n",
        "    g_final = np.array(g_selected_list).reshape(-1, 1) # M0 x 1\n",
        "\n",
        "    theta_FROLS = np.array([])\n",
        "    if A_final.size > 0:\n",
        "        try:\n",
        "            theta_FROLS = np.linalg.solve(A_final, g_final)\n",
        "        except np.linalg.LinAlgError: # Should not happen if A is well-formed (upper triangular with 1s)\n",
        "            theta_FROLS = np.linalg.pinv(A_final) @ g_final # Fallback\n",
        "\n",
        "    P_sel_data_final = P_regressors[:, selected_terms_indices]\n",
        "    P_sel_colnames_final = [P_colnames[i] for i in selected_terms_indices] if P_colnames else []\n",
        "\n",
        "    return {\n",
        "        'th': theta_FROLS.flatten(),\n",
        "        'Psel_data': P_sel_data_final,\n",
        "        'Psel_colnames': P_sel_colnames_final,\n",
        "        'g': g_final.flatten(),\n",
        "        'W': Q_orthogonal_bases, # Orthogonal basis matrix\n",
        "        'A': A_final,\n",
        "        'ERR_values': np.array(err_selected_list).flatten(),\n",
        "        'selected_indices': selected_terms_indices\n",
        "    }"
      ],
      "metadata": {
        "id": "Fm649r-5Poc-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing FROLS with synthetic data\n",
        "\n",
        "Below we generate synthetic data and then apply FROLS to select the terms.\n",
        "\n",
        "We expect to recover the list of candidate variables as in the synthetic model.\n",
        "\n"
      ],
      "metadata": {
        "id": "vt2YCvroQIko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Generate simulation data ------------------------------------------------\n",
        "N = 200\n",
        "np.random.seed(0) # For reproducibility, optional\n",
        "u_sim = np.random.uniform(low=-1, high=1, size=N)\n",
        "e_sim = np.random.normal(loc=0, scale=0.1, size=N)\n",
        "y_sim = np.zeros(N)\n",
        "\n",
        "# NARX process:\n",
        "# y[k] = -0.605*y[k-1] - 0.163*y[k-2]^2 + 0.588*u[k-1] - 0.24*u[k-2] + e[k]\n",
        "# Indices for y_sim and u_sim are 0-based.\n",
        "# k_idx corresponds to current time 'k'.\n",
        "# y_sim[k_idx-1] is y(k-1), y_sim[k_idx-2] is y(k-2)\n",
        "# u_sim[k_idx-1] is u(k-1), u_sim[k_idx-2] is u(k-2)\n",
        "for k_idx in range(2, N): # Start from k_idx=2 (3rd element, time k=3 if 1-indexed)\n",
        "    y_sim[k_idx] = (\n",
        "        -0.605 * y_sim[k_idx-1]\n",
        "        - 0.163 * (y_sim[k_idx-2]**2)\n",
        "        + 0.588 * u_sim[k_idx-1]\n",
        "        - 0.24 * u_sim[k_idx-2]\n",
        "        + e_sim[k_idx]\n",
        "    )\n",
        "\n",
        "# 2. Model parameters --------------------------------------------------------\n",
        "rho_threshold = 0.03 # ESR < 3%\n",
        "nu_order = 2\n",
        "ny_order = 2\n",
        "# ne_order = 0 # Not explicitly used in regMatNARX in this context\n",
        "poly_degree_l = 3\n",
        "\n",
        "# 3. Create regression and target matrices -----------------------------------\n",
        "# Python regMatNARX takes (u, y, nu, ny, l) and returns P, P_colnames, Y_target\n",
        "P_candidate_matrix, P_candidate_colnames, Y_target_vector = regMatNARX(\n",
        "    u_sim, y_sim, nu_order, ny_order, poly_degree_l\n",
        ")\n",
        "\n",
        "# 4. FROLS term selection and parameter estimation ---------------------------\n",
        "frols_results = frols(\n",
        "    P_candidate_matrix,\n",
        "    Y_target_vector,\n",
        "    rho_threshold,\n",
        "    P_candidate_colnames\n",
        ")\n",
        "\n",
        "# 5. Print important information ---------------------------------------------\n",
        "print(\"--- FROLS Results ---\")\n",
        "print(\"\\nSelected terms:\")\n",
        "if frols_results['Psel_colnames']:\n",
        "    for i, term_name in enumerate(frols_results['Psel_colnames']):\n",
        "        print(f\"  {i+1}. {term_name}\")\n",
        "else:\n",
        "    print(\"  No terms selected.\")\n",
        "\n",
        "print(\"\\nEstimated parameters (theta):\")\n",
        "if frols_results['th'].size > 0:\n",
        "    for i, param_val in enumerate(frols_results['th']):\n",
        "        term_name = frols_results['Psel_colnames'][i] if frols_results['Psel_colnames'] else f\"Term {i+1}\"\n",
        "        print(f\"  {term_name}: {param_val:.4f}\")\n",
        "else:\n",
        "    print(\"  No parameters estimated.\")\n",
        "\n",
        "print(\"\\nERR values for selected terms (%):\")\n",
        "if frols_results['ERR_values'].size > 0:\n",
        "    for i, err_val in enumerate(frols_results['ERR_values']):\n",
        "        term_name = frols_results['Psel_colnames'][i] if frols_results['Psel_colnames'] else f\"Term {i+1}\"\n",
        "        print(f\"  {term_name}: {err_val * 100:.2f}%\")\n",
        "else:\n",
        "    print(\"  No ERR values.\")\n",
        "\n",
        "# You can access other results like:\n",
        "# frols_results['Psel_data'] # Matrix of selected regressors\n",
        "# frols_results['W']         # Orthogonal basis matrix\n",
        "# frols_results['A']         # Transformation matrix A\n",
        "# frols_results['g']         # Parameters g for orthogonal model\n",
        "# frols_results['selected_indices'] # 0-based indices of selected terms from P_candidate_matrix"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rw7RP7qCQDO1",
        "outputId": "33f6809b-1a42-4aff-dcc8-8eacc1b1f3ad"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- FROLS Results ---\n",
            "\n",
            "Selected terms:\n",
            "  1. y(k-1)\n",
            "  2. u(k-1)\n",
            "  3. y(k-2)y(k-2)\n",
            "  4. u(k-2)\n",
            "\n",
            "Estimated parameters (theta):\n",
            "  y(k-1): -0.6150\n",
            "  u(k-1): 0.5739\n",
            "  y(k-2)y(k-2): -0.1872\n",
            "  u(k-2): -0.2361\n",
            "\n",
            "ERR values for selected terms (%):\n",
            "  y(k-1): 69.66%\n",
            "  u(k-1): 21.30%\n",
            "  y(k-2)y(k-2): 4.77%\n",
            "  u(k-2): 2.37%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are comparable with Table 3.3 in Billings' book. We used herein ESR (rho) of 3%."
      ],
      "metadata": {
        "id": "TWfDtiOYRz8b"
      }
    }
  ]
}